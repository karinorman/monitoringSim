---
title: "Environmental Evaluaiton"
output: html_document
date: '2022-06-27'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(hypervolume)
library(dplyr)
library(tidyr)
library(purrr)
library(sf)
```

Get selected points and landcover data
```{r}
load(here::here("data/env_pts_data.rda")) #environmental data for each point
load(here::here("data/samplesize_sim.rda"))
load(here::here("data/strata_sim_points.rda"))
```

Look at correlation
```{r}
#pairs(dplyr::select(env_pts_data[,1:10], -ID))
```

```{r}

#PCA of the variables to reduce the dimensionality
envdata <- env_pts_data %>% 
  select(-starts_with(c("silvis", "ghmts")), -x) %>%
  drop_na()

env_pca <- ade4::dudi.pca(df = dplyr::select(envdata, -ID), 
  center = TRUE, scale = TRUE, scannf = FALSE, nf = 3)

env_pc <- as.data.frame(env_pca$li) %>%
  cbind(ID = envdata$ID, .)

# envdata_scale <- env_pts_data %>% 
#   select(-ID, -can_lc_proj) %>%
#   mutate(across(everything(), ~scale(.x)))

comp_hyp <- hypervolume(env_pca$li)

# example comparison but taking a random subset of points

envdata_samp <- sample_n(env_pca$li, 500)
samp_hyp <- hypervolume(envdata_samp)

overlap <- hypervolume_set(comp_hyp, samp_hyp, check.memory = FALSE)
hypervolume_overlap_statistics(overlap)
```

Need to figure out if the hypervolumes and metrics are behaving the way they should
```{r}
# Let's make increasingly larger subsets of the original hypervolume

samp_props <- c(0.02, 0.05, 0.10, 0.25, 0.50, 0.75)

get_prop_overlap <- function(samp_prop, comp_hyp, env_data){
  subset_data <- slice_sample(env_data, prop = samp_prop)
  subset_hyp <- hypervolume(subset_data)
  
  overlap <- hypervolume_set(comp_hyp, subset_hyp, check.memory = FALSE)
  hypervolume_overlap_statistics(overlap)
}

sim_df <- map_df(samp_props, get_prop_overlap, comp_hyp = comp_hyp, env_data = env_pca$li) %>%
  cbind(samp_props, .)

```
Ok so things look as they should.

Let's try with the actual simulated samples
```{r}
# get a hypervolume for each of the simulation replicates

# get a list of the point subsets for each simid (a list of df's)
pca_dfs <- samplesize_sim %>%
  select(-x) %>%
  group_by(simid) %>%
 # purrr::set_names() %>%
  group_map(., ~ setNames(list(env_pc %>%
              filter(ID %in% .x$id) %>%
              dplyr::select(-ID)), unique(.x$simid)), .keep = TRUE)



# get the hypervolume for each
hypervolume_safe <- possibly(hypervolume, NA)

plan("multisession", workers = 120)

sample_hyps <- furrr::future_map(pca_dfs, ~setNames(list(hypervolume_safe(.x[[1]])), names(.x)), 
                                 .options = furrr_options(seed = TRUE))
  
  
# get overlap stats between simulated hypervolumes and the complete environmental hypervolume
overlap_stats <- map_dfr(sample_hyps, ~hypervolume_set(comp_hyp, .x[[1]], check.memory = FALSE) %>%
                           hypervolume_overlap_statistics() %>% c(., simid = names(.x))) 

overlap_stats %>%
  separate(simid, "_", into = c("rep", "sample_size", "algorithm")) %>%
  mutate(across(-c(algorithm), ~as.numeric(.))) %>%
  group_by(sample_size, algorithm) %>%
  summarize(mean = mean(jaccard), sd = sd(jaccard), .groups = "keep") %>%
  ungroup(sample_size) %>%
  ggplot(aes(x = sample_size, y = mean, color = algorithm)) +
  geom_line() +
  labs(y ="Mean env coverage", x = "Sample Size") 
```


Jensen-shannon divergence of the env axes

Do it for one variable
```{r}
binned_data <- envdata %>% 
  select(ID, chelsa.climbio10_1981) %>%
  mutate(bins = cut_interval(chelsa.climbio10_1981, n = 10, labels = FALSE)) #%>%
  # separate(bins, ",", into = c("start", "end"), remove = FALSE) %>%
  # mutate(start = stringr::str_sub(start, 2),
  #        end = stringr::str_sub(end, 1, -2))

total_dist <- binned_data %>% 
  count(bins) %>% 
  pivot_wider(names_from = bins, values_from = n, values_fill = 0) %>%
  mutate(simid = "total")

sim_dist <- strata_sim_points %>%
  select(colnames(samplesize_sim)) %>%
  mutate(sim_type = "stratified_equal_prob") %>%
  bind_rows(samplesize_sim %>% mutate(sim_type = "equal_prob")) %>%
  left_join(binned_data, by = c("id" = "ID")) %>% 
  group_by(simid, sim_type) %>% 
  count(bins) %>% 
  pivot_wider(names_from = bins, values_from = n, values_fill = 0) %>%
  bind_rows(total_dist) %>%
  ungroup() #%>%
  #tibble::column_to_rownames("simid")
  
jsd <- philentropy::JSD(as.matrix(select(sim_dist, - simid)), est.prob = "empirical") %>%
  as_tibble() %>%
  bind_cols(sim_dist$simid, .)

colnames(jsd) <- c("simid", sim_dist$simid)

comp_total <- select(jsd, simid, total) %>%
  filter(simid != "total")
```

Plot 
```{r}

comp_total %>%
  separate(simid, "_", into = c("rep", "sample_size", "algorithm")) %>%
  mutate(across(-c(algorithm), ~as.numeric(.))) %>%
  group_by(sample_size, algorithm) %>%
  summarize(mean = mean(total), sd = sd(total), .groups = "keep") %>%
  ungroup(sample_size) %>%
  ggplot(aes(x = sample_size, y = mean, color = algorithm)) +
  geom_line() +
  labs(y ="Mean env coverage", x = "Sample Size") 
```

Function to map across variables
```{r}
get_var_jsd <- function(env_data, var_name, sample_data){
  binned_data <- env_data %>% 
  select(ID, !!var_name) %>%
  mutate(bins = cut_interval(!!sym(var_name), n = 10, labels = FALSE)) 

total_dist <- binned_data %>% 
  count(bins) %>% 
  pivot_wider(names_from = bins, values_from = n, values_fill = 0) %>%
  mutate(temp_id = var_name)

sim_dist <- left_join(sample_data, binned_data, by = c("id" = "ID")) %>% 
  group_by(simid, sim_type) %>% 
  count(bins) %>% 
  pivot_wider(names_from = bins, values_from = n, values_fill = 0) %>%
  ungroup() %>%
  unite( col = "temp_id", simid, sim_type, sep = "-") %>% 
  bind_rows(total_dist)
  
jsd <- philentropy::JSD(as.matrix(select(sim_dist, -temp_id)), est.prob = "empirical") %>%
  as_tibble() %>%
  bind_cols(sim_dist$temp_id, .)

colnames(jsd) <- c("temp_id", sim_dist$temp_id)

comp_total <- select(jsd, temp_id, !!sym(var_name)) %>%
  filter(temp_id != var_name) %>%
  separate(temp_id, into = c("simid", "sim_type"), sep = "-")
}

#get_var_jsd(envdata, "chelsa.climbio10_1981")
```

Get JSD for all variables 
```{r}
comb_sim_df <- strata_sim_points %>%
  select(colnames(samplesize_sim)) %>%
  mutate(sim_type = "stratified_equal_prob") %>%
  bind_rows(samplesize_sim %>% mutate(sim_type = "equal_prob"))

env_vars <- envdata %>% select(-ID) %>% colnames()

env_vars_jsd <- map(env_vars, ~get_var_jsd(env_data = envdata, var_name = .x, sample_data = comb_sim_df)) %>% 
  reduce(full_join, by = "simid") 

usethis::use_data(env_vars_jsd)
```

Plot for all variables
```{r}
jsd_long <- env_vars_jsd %>%
  separate(simid, "_", into = c("rep", "sample_size", "algorithm")) %>%
  mutate(across(-c(algorithm), ~as.numeric(.))) %>%
  group_by(sample_size, algorithm) %>%
  summarize(across(-rep, ~mean(.x)), .groups = "keep") %>%
  ungroup() %>%
  pivot_longer(c(everything(), -sample_size, -algorithm), names_to = "env_variable")

# plot the variables individually
 jsd_long %>% 
  ggplot(aes(x = sample_size, y = value, color = algorithm)) +
  geom_line() +
  facet_wrap(vars(env_variable)) +
  labs(y ="Mean env coverage", x = "Sample Size") 

# plot the average across variables
jsd_long %>%
  group_by(sample_size, algorithm) %>%
  summarize(mean_jsd = mean(value), .groups = "keep") %>%
  ggplot(aes(x = sample_size, y = mean_jsd, color = algorithm)) +
  geom_line() +
  labs(y ="Mean env coverage", x = "Sample Size") 
```




