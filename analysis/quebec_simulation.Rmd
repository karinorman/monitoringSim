---
title: "Quebec Sim"
output: html_document
date: '2022-07-06'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
library(tidyr)
library(furrr)
library(sf)
library(survey)
library(spsurvey)
library(BalancedSampling)
library(sampling)

devtools::load_all()
```

Load Data
```{r}
load(here::here("data/qc.rda"))
qc_proj <- st_transform(qc, crs = 5070)
```

Set up simulation for Quebec
```{r}
#number of points
n <- 100
#number of replicates for a single sample size
repn <- 100

#list of sample sizes
sample_sizes <- c(10, 20, 50, 100, 500, 1000, 5000)

# to get more candidate points (increase N), larger pt_density 
qc_cand_points <- get_cand_points(qc_proj, n, pt_density = 100)

usethis::use_data(qc_cand_points)
```

## Equal probability sampling
```{r}
##FIXME probably move this function out of the script and name it more usefully
get_eqprop_reps <- function(n, N, pt_df, nreps) {
  
   pik <- rep(n/N,N) #vector of inclusion probabilities
   pt_mat <- as.matrix(cbind(sf::st_coordinates(pt_df)[,1],
                       sf::st_coordinates(pt_df)[,2]))
   
   purrr::map_dfr(1:nreps, 
                 function(rep) {
                   print(c(rep, n))
                   get_eqprob(sf_df = pt_df, pt_mat = pt_mat,
                              n = n, pik = pik) %>% 
                     mutate(rep = rep)
                 })
}

# test run
# N <- dim(qc_cand_points)[1]
# samplesize_sim <- purrr::map_dfr(sample_sizes[1:2], ~get_eqprop_reps(.x, N = N, pt_df = qc_cand_points, nreps = 2) %>% mutate(sample_size = .x))

# Parallelize Version
#options(future.debug = FALSE)
#have to source internal functions so the workers can see them
source(here::here("R/get_eqprob.R"))
N <- dim(qc_cand_points)[1]

plan("multisession", workers = length(sample_sizes))
samplesize_sim <- furrr::future_map_dfr(sample_sizes, 
                                        ~get_eqprop_reps(.x, N = N, pt_df = qc_cand_points, nreps = repn) %>% 
                                          mutate(sample_size = .x),
                                        .options = furrr_options(packages = "monitoringSim",  
                                        seed = TRUE))  %>% 
    unite("simid", rep, sample_size, algorithm, remove = FALSE)

usethis::use_data(samplesize_sim)
```

## Stratified Equal Probability sampling
```{r}
library(sf)

#get ecoregion data
ecoreg <- st_read(here::here("data/wwf_ecoregions/wwf_terr_ecos.shp")) %>%
  st_transform(ecoreg, crs = 5070) %>%
  st_make_valid()

# make sure CRS matches candidate points
raster::compareCRS(ecoreg, qc_cand_points)

# get the ecoregion for each point
ecoreg_pts <- st_intersection(qc_cand_points, ecoreg)

usethis::use_data(ecoreg_pts)
```

How many points are in each ecoregion? Exclude ecoregions with very few points
```{r}
inc_ecoreg_pts <- ecoreg_pts %>% 
  count(ECO_NUM) %>%
  filter(n > 10)
```

What area does each ecoregion cover?
```{r}
#clip the shapefile to quebec (study frame) to get are
ecoreg_qc <- st_intersection(ecoreg, qc_proj)
ecoreg_qc$AREA <- st_area(ecoreg_qc)

#https://stackoverflow.com/questions/69539592/calculate-the-surface-area-of-a-variable-in-a-shapefile-in-r#:~:text=Load%20your%20multipolygon%20in%20R,(row)%20in%20your%20multipolygon.&text=%3E%20df2,%3D%20%22id%22%2C%20all.

ecoreg_areas <- ecoreg_qc %>% 
  filter(ECO_NUM %in% ecoreg_pts$ECO_NUM) %>% #exclude regions with too few points
  group_by(ECO_NUM) %>% 
  summarize(st_union(geometry), 
            area_NAME = sum(AREA)) %>%
  mutate(PERC_AREA = area_NAME/sum(area_NAME))

```

Format ecoregion and point data
```{r}
inc_pts <- ecoreg_pts %>% 
  filter(ECO_NUM %in% inc_ecoreg_pts$ECO_NUM) %>% #exclude ecoregions with too few points
  arrange(id)

#get count of points in each ecoregion (N_stratum)
stratum_counts <- inc_pts %>%
  count(ECO_NUM, name = "N") %>%
  st_drop_geometry()

num_strata <- n_distinct(inc_pts$ECO_NUM)

equal_samp <- rep(n/num_strata, num_strata)
prop_samp <- ecoreg_areas %>% 
  mutate(sample_size = as.integer(round(PERC_AREA * n))) %>%
  left_join(stratum_counts) %>%
  mutate(inc_prop = sample_size/N)

ecoregion_points_data <- inc_pts %>%
  left_join(st_drop_geometry(prop_samp))%>%
  arrange(id)

usethis::use_data(ecoregion_points_data)
```

Stratification function
```{r}
# need to fix hardcoding of column names
get_eqprob_strat <- function(pt_df, n, N){
  
  # process ecoregion dataframe #
  #get count of points in each ecoregion (N_stratum)
  stratum_counts <- inc_pts %>%
    count(ECO_NUM, name = "N") %>%
    st_drop_geometry()
  
  num_strata <- n_distinct(inc_pts$ECO_NUM)
  
  N <- n_distinct(pt_df$id)
  coord_mat <- as.matrix(sf::st_coordinates(inc_pts)[,1], sf::st_coordinates(inc_pts)[,2])
  prob_vec <- pt_df$inc_prop
  
    strata_n <- pt_df %>%
    st_drop_geometry() %>%
    select(ECO_NUM, sample_size) %>%
    distinct() %>%
    tibble::deframe()
    
  strata_n <- strata_n[order(as.integer(names(strata_n)))]
  
  #simple random sampling stratified
  srs <- sampling::strata(data = pt_df %>% arrange(ECO_NUM), stratanames = c("ECO_NUM"),
                size = strata_n, method = "srswr")
  
  # GRTS
  grts_strat <- spsurvey::grts(pt_df, n_base = strata_n, stratum_var = "ECO_NUM")
  
  # CUBE
  cube_strat <- BalancedSampling::cubestratified(prob = prob_vec, Xbal = coord_mat, integerStrata = inc_pts$ECO_NUM)
  
  # SCPS
  scps_strat <- pt_df %>%
    group_by(ECO_NUM) %>%
    group_map(~{
      prob <- .x$inc_prop
      x <- as.matrix(sf::st_coordinates(.x)[,1], sf::st_coordinates(.x)[,2])
      
      return(BalancedSampling::scps(prob, x))
    }) %>% unlist()
  
  lpm1_strat <- pt_df %>%
    group_by(ECO_NUM) %>%
    group_map(~{
      prob <- .x$inc_prop
      x <- as.matrix(sf::st_coordinates(.x)[,1], sf::st_coordinates(.x)[,2])
      
      return(BalancedSampling::lpm1(prob, x))
    }) %>% unlist()
  
  lpm2_strat <- pt_df %>%
    group_by(ECO_NUM) %>%
    group_map(~{
      prob <- .x$inc_prop
      x <- as.matrix(sf::st_coordinates(.x)[,1], sf::st_coordinates(.x)[,2])
      
      return(BalancedSampling::lpm2(prob, x))
    }) %>% unlist()
  
  list(srs = which(srs == 1), grts = grts_strat$sites_base$id, cube = which(cube_strat == 1),
       scps = scps_strat, lpm1 = lpm1_strat, lpm2 = lpm2_strat) %>%
    map_dfr(., ~as.data.frame(.x), .id = "algorithm") %>%
    rename(id = `.x`) %>%
    left_join(pt_df)
}

```

SRS with stratification by ecoregion
```{r}

strata(inc_pts, 
                 stratanames = c("ECO_NUM"), 
                 size = equal_samp, method = "srswr")

# make sure the stratification variable is in the same order for data and sample sizes
srs_strat <- strata(data = inc_pts %>% arrange(ECO_NUM), stratanames = c("ECO_NUM"),
                 size = as.integer(prop_samp$sample_size), method = "srswr")

```
GRTS algorithm

```{r}
strata_n <- prop_samp %>%
  select(ECO_NUM, sample_size) %>%
  st_drop_geometry() %>%
  tibble::deframe()

grts_strat <- grts(inc_pts, n_base = strata_n, stratum_var = "ECO_NUM")

selected_sites <- grts_strat$sites_base
```

Cube sampling
```{r}
#library(BalancedSampling)

N <- n_distinct(inc_pts$id)
coord_mat <- as.matrix(sf::st_coordinates(inc_pts)[,1], sf::st_coordinates(inc_pts)[,2])
prob_vec <- inc_pts$inc_prop

cube_strat <- cubestratified(prob = prob_vec, Xbal = coord_mat, integerStrata = inc_pts$ECO_NUM)
```

Both SCPS and LPM do not have built in stratification approaches, so we'll brute force it
```{r}
scps_strat <- inc_pts %>%
  group_by(ECO_NUM) %>%
  group_map(~{
    prob <- .x$inc_prop
    x <- as.matrix(sf::st_coordinates(.x)[,1], sf::st_coordinates(.x)[,2])
    
    return(scps(prob, x))
  })

lpm1_strat <- inc_pts %>%
  group_by(ECO_NUM) %>%
  group_map(~{
    prob <- .x$inc_prop
    x <- as.matrix(sf::st_coordinates(.x)[,1], sf::st_coordinates(.x)[,2])
    
    return(lpm1(prob, x))
  })

lpm2_strat <- inc_pts %>%
  group_by(ECO_NUM) %>%
  group_map(~{
    prob <- .x$inc_prop
    x <- as.matrix(sf::st_coordinates(.x)[,1], sf::st_coordinates(.x)[,2])
    
    return(lpm2(prob, x))
  })
```




