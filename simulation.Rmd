---
title: "Simple Simulation"
output: html_document
date: '2022-05-12'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Let's do a little example simulation to build some of the infrastructure

```{r}
library(dplyr)
library(tidyr)
library(survey)
library(spsurvey)
library(BalancedSampling)

devtools::load_all()
```

This is the simulation example from the Benedetti 2015 textbook
```{r}
#number of sites
n <- 100
#number of possible sites
N <- 1000

set.seed(12412)

simdf <- data.frame(id = 1:N, x = runif(N), y = runif(N))

#create survey variable yobs with spatial trend on the coordinates
yobs <- (exp((simdf$x-0.5)^2)+exp((simdf$y-0.5)^2))
#add some noise
yobs <- 100-((yobs-min(yobs))/(max(yobs-min(yobs))))*100+
+ (rnorm(N)+5)*5
ypps <- exp(yobs/10) #continuous variable
q1obs <- sample(1:3,N,replace = TRUE) #categorical variable
q2obs <- sample(LETTERS[1:2], N, replace = TRUE) #categorical variable
simdf <- cbind(simdf,yobs,ypps,q1obs,q2obs)

#distance matrix for candidate sites
dist_mat <- as.matrix(dist(simdf %>% select(x, y)))


#inclusion probs and df of cooridnates are often inputs
pik <- rep(n/N,N) #vector of inclusion probabilities
x <- as.matrix(cbind(simdf$x,simdf$y))
```

Let's fit equal probability sample using all the algorithms
```{r}
# first get spatial df for GRTS function
simdf_sf <- st_as_sf(simdf, coords = c("x", "y"), crs = 4326)
simdf_sf <- st_transform(simdf_sf, crs = 5070)

#GRTS 
grts_eqprob <- grts(simdf_sf, n_base = n)

#Cube sampling
cube_eqprob <- samplecube(x,pik,comment=TRUE,method=1)

#SCPS
scps_eqprob <- scps(pik, x)

#LPM
lpm1_eqprob <- lpm1(pik,x)
lpm2_eqprob <- lpm2(pik,x)

spbalance(dist_mat, rep(n/N,N), grts_eqprob$sites_base$id)

selected_sites <- list(grts = grts_eqprob$sites_base$id, cube = (1:1000)[cube_eqprob==1],
                       scps = scps_eqprob, lpm1 = lpm1_eqprob, lpm2 = lpm2_eqprob)

purrr::map_df(selected_sites, spbalance, dist_mat = dist_mat, pik = pik)
```

Let's try the option where we turn other survey designs into `spdesign` objects from spsurvey

```{r}
# 1. Make a base spdesign object that contains all of the sites 
base_spdes <- grts(simdf_sf, n_base = N)

# #let's turn the cube samples into spdesign object
# cube_ids <- (1:1000)[cube_eqprob==1]
# cube_spdes <- base_spdes 
# cube_spdes$sites_base <- base_spdes$sites_base %>% filter(id %in% cube_ids)
# 
# #update the spdesign$design info
# cube_spdes$design$n_base <- length(cube_ids)
# 
# #### Might need to update spdesign$design$call, see if it becomes a problem #####
```

Maybe I don't even need the whole object? I just need the `sites_base` sf dataframe?

```{r}
all_sites <- base_spdes$sites_base

cube_ids <- (1:1000)[cube_eqprob==1]
cube_sites <- all_sites %>%
  filter(id %in% cube_ids)
```

Alrighty, get all metrics for both designs
```{r}
purrr::map_df(list(grts = grts_eqprob$sites_base, cube = cube_spdes$sites_base), 
              sp_balance, sframe = simdf_sf,
              metrics = c("pielou", "simpsons", "rmse", "mse", "mae", "medae", "chisq"),
              .id = "alg") %>%
  pivot_wider(names_from = "metric", values_from = "value")
```
Let's try for all of the algorithms
```{r}

purrr:::map_dfr(selected_sites, function(x) {
  sites <- all_sites %>% filter(id %in% x)
  sp_balance(sites, simdf_sf, 
             metrics = c("pielou", "simpsons", "rmse", "mse", "mae", "medae", "chisq"))
}, .id = "alg") %>%
  pivot_wider(names_from = "metric", values_from = "value")
```
How about a function to get selected sites from all the algorithms, using the same specifications
```{r}
get_eqprob <- function(sf_df, n, N) {
  
  pik <- rep(n/N,N) #vector of inclusion probabilities

  x <- as.matrix(cbind(sf::st_coordinates(sf_df)[,1],
                sf::st_coordinates(sf_df)[,2]))
  
  # #get matrix of vertices for a bounding box of the sample area
  # bb <- st_bbox(sf_df)
  # bmat <- matrix(c(bb$xmin, bb$ymin,
  #                  bb$xmin, bb$ymax,
  #                  bb$xmax, bb$ymax,
  #                  bb$xmax, bb$ymax),
  #                ncol = 2, byrow = TRUE)
  
  #Simple random sample
  srs <- srswor(n, N)
  
  #GRTS
  grts_fit <- grts(sf_df, n_base = n)
  
  #Cube sampling
  cube_fit <- samplecube(x, pik, comment = TRUE, method = 1)
  
  #SCPS
  scps_fit <- scps(pik, x)
  
  #LPM
  lpm1_fit <- lpm1(pik, x)
  lpm2_fit <- lpm2(pik, x)
  
  # #BAS
  # bas_fit <- quasiSamp(n, dimension = 2, potential.sites = x, 
  #                      study.area = bmat, inclusion.probs = pik)
  
  list(srs = (1:1000)[srs==1], grts = grts_fit$sites_base$id, cube = (1:1000)[cube_fit==1],
                       scps = scps_fit, lpm1 = lpm1_fit, lpm2 = lpm2_fit)
}


#get dataframe of all the sites in a form the spsurvey::sp_balance likes
base_spdes <- grts(simdf_sf, n_base = N)
all_sites <- base_spdes$sites_base

eqprob <- get_eqprob(simdf_sf, n, N)

eqprob_metrics <- purrr:::map_dfr(eqprob, function(x) {
  # the id column is consistent with the rows of the input dataframe for non grts algorithms, 
  # so we can directly filter that column
  sites <- all_sites %>% filter(id %in% x)
  
  sp_balance(sites, simdf_sf, 
             metrics = c("pielou", "simpsons", "rmse", "mse", "mae", "medae", "chisq"))
}, .id = "alg") %>%
  pivot_wider(names_from = "metric", values_from = "value") %>%
  mutate(efficiency = mse/filter(., alg == "srs") %>% pull(mse))

```

Let's try a full example sampling an area instead of a population.
```{r}
set.seed(12412)

#Get example shapefile of the central valley
valley <- st_read(here::here("data/greatvalley_outline.shp"))

#function for get a set of candidate points for the landscape, adapted from `grts_stratum`
get_cand_points <- function(polygon, n, pt_density = 10){
  # this code is adapted from the spsurvey::grts_stratum function that is not exported, but selects the points for 
  # point, linear, and polygon inputs
  
  #define how many candidate points we want
  n_size <- as.integer(ceiling(pmin(1e+09, pt_density * n)))
  
  #get random points
  cand_points <- st_sample(polygon, size = n_size, type = "hexagonal", 
                   exact = TRUE) %>%
    st_as_sf(as.data.frame(.), crs = st_crs(polygon)) %>%
    st_cast(to = "POINT") %>%
    filter(!st_is_empty(.)) %>%
    st_join(polygon) #get metadata from the polygon 
}

valley_cand_points <- get_cand_points(valley, n)
```

